# Домашнее задание к занятию «Хранение в K8s. Часть 2»

### Цель задания

В тестовой среде Kubernetes нужно создать PV и продемострировать запись и хранение файлов.

------

### Чеклист готовности к домашнему заданию

1. Установленное K8s-решение (например, MicroK8S).
2. Установленный локальный kubectl.
3. Редактор YAML-файлов с подключенным GitHub-репозиторием.

------

### Дополнительные материалы для выполнения задания

1. [Инструкция по установке NFS в MicroK8S](https://microk8s.io/docs/nfs). 
2. [Описание Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/). 
3. [Описание динамического провижининга](https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/). 
4. [Описание Multitool](https://github.com/wbitt/Network-MultiTool).

------

### Задание 1

**Что нужно сделать**

Создать Deployment приложения, использующего локальный PV, созданный вручную.

1. Создать Deployment приложения, состоящего из контейнеров busybox и multitool.
2. Создать PV и PVC для подключения папки на локальной ноде, которая будет использована в поде.
3. Продемонстрировать, что multitool может читать файл, в который busybox пишет каждые пять секунд в общей директории. 
4. Продемонстрировать, что файл сохранился на локальном диске ноды, а также что произойдёт с файлом после удаления пода и deployment. Пояснить, почему.
5. Предоставить манифесты, а также скриншоты или вывод необходимых команд.

------

### Задание 2

**Что нужно сделать**

Создать Deployment приложения, которое может хранить файлы на NFS с динамическим созданием PV.

1. Включить и настроить NFS-сервер на MicroK8S.
2. Создать Deployment приложения состоящего из multitool, и подключить к нему PV, созданный автоматически на сервере NFS.
3. Продемонстрировать возможность чтения и записи файла изнутри пода. 
4. Предоставить манифесты, а также скриншоты или вывод необходимых команд.

------

### Правила приёма работы

1. Домашняя работа оформляется в своём Git-репозитории в файле README.md. Выполненное задание пришлите ссылкой на .md-файл в вашем репозитории.
2. Файл README.md должен содержать скриншоты вывода необходимых команд `kubectl`, а также скриншоты результатов.
3. Репозиторий должен содержать тексты манифестов или ссылки на них в файле README.md.






# Выполнение  
### Задание 1  

Создаём **StorageClass**, **PersistentVolume**, **PersistantVolumeClaim** и **Deployment**.  
В них мы описываем **Deployment** с контейнерами, к которым мы мантируем нужный нам том и пишем туда какой-то вывод.  
Мы делаем это с помощью **PersistantVolumeClaim** который через **StorageClass** монтирует наш **PersistentVolume**  

<details>

  <summary><b>storage-class.yml</b></summary>
  
```yml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
```
</details>


<details>

  <summary><b>persistent-volume.yml</b></summary>
  
```yml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv
spec:
  storageClassName: local-storage
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  hostPath:
    path: /PV
  persistentVolumeReclaimPolicy: Retain
```
  
</details>


<details>

  <summary><b>persistent-volume-claim.yml</b></summary>
  
```yml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: netologypvc
spec:
  storageClassName: local-storage
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  volumeName: pv
```
  
</details>


<details>

  <summary><b>deployment-volume-2.yml</b></summary>
  
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netology-deployment-volume
  labels:
    app: netology-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: netology-app
  template:
    metadata:
      labels:
        app: netology-app
    spec:
      volumes:
      - name: my-volume
        persistentVolumeClaim:
          claimName: netologypvc
      containers:
      - name: busybox
        image: busybox
        command: ['sh', '-c', "while true; do date >> /output/output.txt; sleep 5; done"]
        volumeMounts:
        - name: my-volume
          mountPath: /output
      - name: multitool
        image: wbitt/network-multitool
        env:
          - name: HTTP_PORT
            value: "8080"
          - name: HTTPS_PORT
            value: "11443"
        ports:
        - containerPort: 8080
        - containerPort: 11443
        volumeMounts:
        - name: my-volume
          mountPath: /input
```

</details>

Запускаем  
```
microk8s kubectl apply -f storage-class.yml
microk8s kubectl apply -f persistent-volume.yml
microk8s kubectl apply -f persistent-volume-claim.yml
microk8s kubectl apply -f deployment-volume-2.yml
```
Узнаём имя пода и логинимся в контейнер с multitool  
```
microk8s kubectl exec -it netology-deployment-volume-69c844f6ff-q9t6g -c multitool -- /bin/sh
```
Подождём пока нагенерятся логи, зайдём в примонтированную папку и проверим что там  
```
/input # cat output.txt
```
```
Wed Apr 26 16:04:05 UTC 2023
Wed Apr 26 16:04:10 UTC 2023
Wed Apr 26 16:04:15 UTC 2023
```
Повторим и увидим изменения
```
Wed Apr 26 16:04:20 UTC 2023
Wed Apr 26 16:04:25 UTC 2023
Wed Apr 26 16:04:30 UTC 2023
```
Вывод пишется в PV который видят оба контейнера.  
Удалим деплоймент  
```
microk8s kubectl delete deployment netology-deployment-volume
```
Проверим наш PV
```
microk8s kubectl get persistentvolume
```
```
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS    REASON   AGE
pv     1Gi        RWX            Retain           Bound    default/netologypvc   local-storage            3h35m
```
Найдём директорию на которую ссылается PV
```
igor@ubuntu20:~$ cd /PV
igor@ubuntu20:/PV$ ls
output.txt
```
Наш файл на месте даже после удаление деплоймента.  
Так произошло потому, что в **persistent-volume.yml** мы задали политику сохранения в строчке  
```yml
persistentVolumeReclaimPolicy: Retain
```
### Задание 2   

В случае, если в системе не установлены необходимые пакеты установим их
```
sudo apt-get install nfs-kernel-server
```
Создадим папку под шару
```
sudo mkdir /nfs
```
Подправим конфиг, что бы дать к ней разрешения
```
sudo nano /etc/exports
```
```
/nfs *(rw,sync,no_subtree_check)
```
Перезапустим службу
```
sudo systemctl restart nfs-kernel-server
```
Установим всё необходимое в microk8s
```
microk8s enable community
```
```
microk8s enable nfs
```
```
sudo apt install -y nfs-common
```

Мы подняли NFS сервер на локальной машине и настроили microk8s для работы с ним.  
Теперь мы создадим **PV** и **PVC** указав в них **StorageClass** "nfs" с указанием нашего сервера и подправим наш **deployment**  
В случае с NFS мы можем не создавать отдельный StorageClass  


<details>

  <summary><b>persistent-volume-nfs.yml</b></summary>
```yml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pvnfs
spec:
  storageClassName: nfs
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    path: /nfs
    server: localhost

```
  
</details>


<details>

  <summary><b>persistent-volume-claim-nfs.yml</b></summary>
```yml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pvcnfs
spec:
  storageClassName: nfs
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
```

</details>


<details>

  <summary><b>deployment-volume-nfs.yml</b></summary>
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netology-deployment-volume
  labels:
    app: netology-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: netology-app
  template:
    metadata:
      labels:
        app: netology-app
    spec:
      volumes:
      - name: nfs-volume
        persistentVolumeClaim:
          claimName: pvcnfs
      containers:
      - name: busybox
        image: busybox
        command: ['sh', '-c', "while true; do date >> /output/output.txt; sleep 5; done"]
        volumeMounts:
        - name: nfs-volume
          mountPath: /output
      - name: multitool
        image: wbitt/network-multitool
        env:
          - name: HTTP_PORT
            value: "8080"
          - name: HTTPS_PORT
            value: "11443"
        ports:
        - containerPort: 8080
        - containerPort: 11443
        volumeMounts:
        - name: nfs-volume
          mountPath: /input
```


</details>

