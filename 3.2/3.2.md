# Домашнее задание к занятию "Установка кластера K8s"

### Цель задания

Установить кластер K8s.

### Чеклист готовности к домашнему заданию

1. Развернутые ВМ с ОС Ubuntu 20.04-lts


### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания

1. [Инструкция по установке kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)
2. [Документация kubespray](https://kubespray.io/)

-----

### Задание 1. Установить кластер k8s с 1 master node

1. Подготовка работы кластера из 5 нод: 1 мастер и 4 рабочие ноды.
2. В качестве CRI — containerd.
3. Запуск etcd производить на мастере.
4. Способ установки выбрать самостоятельно.

## Дополнительные задания (со звездочкой*)

**Настоятельно рекомендуем выполнять все задания под звёздочкой.**   Их выполнение поможет глубже разобраться в материале.   
Задания под звёздочкой дополнительные (необязательные к выполнению) и никак не повлияют на получение вами зачета по этому домашнему заданию. 

------
### Задание 2*. Установить HA кластер

1. Установить кластер в режиме HA
2. Использовать нечетное кол-во Master-node
3. Для cluster ip использовать keepalived или другой способ

### Правила приема работы

1. Домашняя работа оформляется в своем Git репозитории в файле README.md. Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
2. Файл README.md должен содержать скриншоты вывода необходимых команд `kubectl get nodes`, а также скриншоты результатов
3. Репозиторий должен содержать тексты манифестов или ссылки на них в файле README.md

# Выполнение
## Задание 1  kubeadm
Сгенерируем ключи для использования их на облачных машинах
```
ssh-keygen -t rsa -b 4096 -f /home/igor/.ssh/yandex/ya_key
```
Создадим мастер ноду в яндекс клауде пробросив наши ключи  
```
yc compute instance create \
--name masternode \
--hostname masternode \
--zone ru-central1-a \
--network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
--create-boot-disk image-folder-id=standard-images,image-family=ubuntu-2004-lts,size=10 \
--ssh-key /home/igor/.ssh/yandex/ya_key.pub \
--format json | jq -r '.network_interfaces[0].primary_v4_address.one_to_one_nat.address'
```
Подключимся по ssh
```
ssh -i /home/igor/.ssh/yandex/ya_key yc-user@158.160.53.7
```
В документации сказано, что для корректной работы обязательно нужно отключить swap.  
Отключим до перезагрузки  
```
sudo swapoff -a
```
Так же откорректируем конфигурационный файл, который будет перечитываться при перезагрузке, что бы свап не включился обратно  
```
sudo nano /etc/fstab
```
Закомментируем строку
```
#UUID=be2c7c06-cc2b-4d4b-96c6-e3700932b129 /               ext4    errors=remount-ro 0       1
```
Воспользуемся коммандами из инструкции
```
mkdir -p 0755 /etc/apt/keyrings && \ #for ubuntu 22.04 and latest
sudo apt-get update && \
sudo apt-get install -y apt-transport-https ca-certificates curl && \
curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg && \
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list && \
sudo apt-get update && \
sudo apt-get install -y kubelet kubeadm kubectl containerd && \
sudo apt-mark hold kubelet kubeadm kubectl containerd
```
Включаем forwarding. Если необходимо зайдём под рутом `sudo -i`  
```
modprobe br_netfilter && \
echo "net.ipv4.ip_forward=1" >> /etc/sysctl.conf && \
echo "net.bridge.bridge-nf-call-iptables=1" >> /etc/sysctl.conf && \
echo "net.bridge.bridge-nf-call-arptables=1" >> /etc/sysctl.conf && \
echo "net.bridge.bridge-nf-call-ip6tables=1" >> /etc/sysctl.conf && \
sysctl -p /etc/sysctl.conf
```
Инициализируем мастер ноду с помощью комманды
```
kubeadm init \
--apiserver-advertise-address=10.128.0.17 \ #внутренний IP нашей машины
--pod-network-cidr 10.244.0.0/16 \ #подсеть, в данном случае стандартная для кубера
--apiserver-cert-extra-sans=158.160.53.7 #внешний IP на случай, если мы хотим подключаться к API кластера из вне
#--control-plane-endpoint=cluster_ip_address #Этот флаг необходим только в случае, если у нас несколько мастер нод и нам нужна единая точка входа для него
```
```
kubeadm init \
--apiserver-advertise-address=10.128.0.17 \
--pod-network-cidr 10.244.0.0/16 \
--apiserver-cert-extra-sans=158.160.53.7
```




